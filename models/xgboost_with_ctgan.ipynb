{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import mlflow\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#ProfileReport(train, title=\"Profiling Report\")\n",
    "\n",
    "#drop some vars\n",
    "drop_list = ['PassengerId', 'Name', 'Cabin']\n",
    "train = train.drop(drop_list, axis=1)\n",
    "train = train.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_list = ['HomePlanet', 'Destination', 'CryoSleep', 'VIP', 'Transported']\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# インスタンス化\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "for column in onehot_list:\n",
    "    # OneHotエンコーディングを適用\n",
    "    transformed = enc.fit_transform(train[[column]])\n",
    "    \n",
    "    # エンコーディングされたデータをDataFrameに変換\n",
    "    transformed_df = pd.DataFrame(transformed, columns=[f\"{column}_{cat}\" for cat in enc.categories_[0]], index=train.index)  # インデックスを指定\n",
    "    \n",
    "    # 元のデータから対象の列を削除\n",
    "    train = train.drop(column, axis=1)\n",
    "    \n",
    "    # エンコーディングされたデータを元のDataFrameに結合\n",
    "    train = pd.concat([train, transformed_df], axis=1)\n",
    "\n",
    "train = train.drop(['HomePlanet_Mars', 'Destination_TRAPPIST-1e', 'CryoSleep_False', 'VIP_False', 'Transported_False'], axis=1)\n",
    "train.head()\n",
    "\n",
    "#説明変数と被説明変数に分割\n",
    "x = train.drop(['Transported_True'], axis=1)\n",
    "y = train['Transported_True']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "train_all = pd.concat([y_train, X_train], axis=1)\n",
    "\n",
    "\n",
    "#cross varidation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "params = {'max_depth':3, 'eta':0.1}\n",
    "cross_val = xgb.cv(\n",
    "    params, dtrain, num_boost_round=1000, early_stopping_rounds=50\n",
    ")\n",
    "best_n_boost_round = cross_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDVによるCTGAN実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SDVによるCT-GAN実装\n",
    "\n",
    "#metadata(json形式)の作成\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=train_all)\n",
    "\n",
    "# CTGANSynthesizerのインスタンスを作成\n",
    "synthesizer = CTGANSynthesizer(metadata)\n",
    "\n",
    "# モデルの学習\n",
    "synthesizer.fit(train_all)\n",
    "\n",
    "#所要時間約10分\n",
    "\n",
    "#synthetic data 作成\n",
    "synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "synthetic_data.head()\n",
    "\n",
    "train_all = pd.concat([train_all, synthetic_data], axis=0)\n",
    "y_train_extended = train_all.iloc[:,0]\n",
    "X_train_extended = train_all.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベイズ最適化による最適パラメータ選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "\n",
    "#pre setting of categorical parameters\n",
    "try_grow_policy = 'depthwise'\n",
    "try_objective = 'reg:squarederror'\n",
    "try_booster = 'gbtree'\n",
    "try_tree_method = 'auto'\n",
    "try_sampling_method = 'uniform'\n",
    "try_importance_type = 'gain'\n",
    "try_device = 'cpu'\n",
    "try_multi_strategy = 'diagonal'\n",
    "try_eval_metric = 'rmse'\n",
    "\n",
    "#evaluation function\n",
    "def xgboost_eval(try_max_depth,try_learning_rate, try_n_estimators, try_gamma, try_min_child_weight, try_subsample, try_colsample_bytree, try_reg_alpha, try_reg_lambda):\n",
    "    # convert to int since these are not continuous variables\n",
    "    try_max_depth = int(try_max_depth)\n",
    "    try_n_estimators = int(try_n_estimators)\n",
    "\n",
    "    #parameter settings\n",
    "    #最大値を設定する系はナシ\n",
    "    #データセットの前処理に関わる変数もナシ。\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=try_max_depth,\n",
    "        learning_rate=try_learning_rate,\n",
    "        n_estimators=try_n_estimators,\n",
    "        gamma=try_gamma,\n",
    "        min_child_weight=try_min_child_weight,\n",
    "        subsample=try_subsample,\n",
    "        colsample_bytree=try_colsample_bytree,\n",
    "        reg_alpha=try_reg_alpha,\n",
    "        reg_lambda=try_reg_lambda,\n",
    "        try_grow_policy = try_grow_policy,\n",
    "        try_objctive = try_objective,\n",
    "        try_booster = try_booster,\n",
    "        try_tree_method = try_tree_method,\n",
    "        try_importance_type = try_importance_type,\n",
    "        try_device = try_device,\n",
    "        try_multi_strategy = try_multi_strategy,\n",
    "        try_eval_metric = try_eval_metric\n",
    "    )\n",
    "    \n",
    "    # model training\n",
    "    model.fit(X_train_extended, y_train_extended)\n",
    "    # calculate model score\n",
    "    score = model.score(X_test, y_test)\n",
    "    #start logging (nested)\n",
    "    with mlflow.start_run(run_name = 'XGBoost',\n",
    "                          experiment_id= experiment,\n",
    "                          nested = True):\n",
    "        #logging settings\n",
    "        mlflow.log_param('max_depth', try_max_depth)\n",
    "        mlflow.log_param('learning_rate', try_learning_rate)\n",
    "        mlflow.log_param('n_estimators', try_n_estimators)\n",
    "        mlflow.log_param('gamma', try_gamma)\n",
    "        mlflow.log_param('min_child_weight', try_min_child_weight)\n",
    "        mlflow.log_param('subsample', try_subsample)\n",
    "        mlflow.log_param('colsample_bytree', try_colsample_bytree)\n",
    "        mlflow.log_param('reg_alpha', try_reg_alpha)\n",
    "        mlflow.log_param('reg_lambda', try_reg_lambda)\n",
    "        mlflow.log_param('grow_policy', try_grow_policy)\n",
    "        mlflow.log_param('objective', try_objective)\n",
    "        mlflow.log_param('booster', try_booster)\n",
    "        mlflow.log_param('tree_method', try_tree_method)\n",
    "        mlflow.log_param('sampling_method', try_sampling_method)\n",
    "        mlflow.log_param('importance_type', try_importance_type)\n",
    "        mlflow.log_param('device', try_device)\n",
    "        mlflow.log_param('multi_strategy', try_multi_strategy)\n",
    "        mlflow.log_param('eval_metric', try_eval_metric)\n",
    "        mlflow.log_metric('score', score)\n",
    "        mlflow.xgboost.log_model(model,'mdoel')\n",
    "        \n",
    "    return score\n",
    "\n",
    "\n",
    "# set search bounds of each parameter\n",
    "pbounds = {\n",
    "    'try_max_depth': (3, 50),\n",
    "    'try_learning_rate': (0.01, 0.5),\n",
    "    'try_n_estimators': (100, 1000),\n",
    "    'try_gamma': (0, 5),\n",
    "    'try_min_child_weight': (1, 10),\n",
    "    'try_subsample': (0.5, 1.0),\n",
    "    'try_colsample_bytree': (0.5, 1.0),\n",
    "    'try_reg_alpha': (0, 1),\n",
    "    'try_reg_lambda': (0, 1)\n",
    "}\n",
    "\n",
    "\n",
    "#create an experiment\n",
    "experiment = mlflow.create_experiment('spaceship_titanic_bayes_opt_extended')\n",
    "\n",
    "#start run experiment\n",
    "with mlflow.start_run(run_name='XGboost',\n",
    "                      experiment_id=experiment):\n",
    "    \n",
    "    #instansation of optimizer\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgboost_eval,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1\n",
    "    )\n",
    "    \n",
    "    #calculation\n",
    "    optimizer.maximize(init_points=5, n_iter=95)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
